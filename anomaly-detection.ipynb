{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcbf0d10-8dd3-4ec8-abae-ca1645b785e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances  # parallelized scipy's pdist \n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import time\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from dtaidistance import dtw_ndim\n",
    "import iisignature\n",
    "\n",
    "# Personal libraries\n",
    "from utils import dyadic_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80e5623",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_data = \"Folder where TS1.txt to TS1000.txt are located\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b1472e4-c4bb-4fb1-a35e-78e9395def77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "CPU times: user 11min 18s, sys: 10min 52s, total: 22min 11s\n",
      "Wall time: 2min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## PARAMS ######################################################################\n",
    "n_outliers = 10\n",
    "n_clusters = 5\n",
    "\n",
    "batch = 260\n",
    "stream = 16\n",
    "channels = 2\n",
    "level = 4\n",
    "dyadic_depth = 3\n",
    "n_simu = 1000\n",
    "\n",
    "lof_params = {'n_neighbors':10,  'metric':'precomputed'} \n",
    "# LOF: no need to set contamination if we want scores \n",
    "################################################################################\n",
    "y_scores = {}\n",
    "y_scores['sig'] = []\n",
    "y_scores['dsig'] = []\n",
    "y_scores['dtw'] = []\n",
    "y_scores['euc'] = []\n",
    "y_trues = []\n",
    "\n",
    "for idx_dataset in range(1, n_simu+1): \n",
    "    if idx_dataset%100==0:\n",
    "        print(idx_dataset)\n",
    "    X_ = np.loadtxt(f\"{folder_data}/TS{idx_dataset}.txt\")\n",
    "    X = np.zeros((batch, stream, channels))\n",
    "    for i in range(batch):\n",
    "        X[i, :, 0] = X_[i, :16]\n",
    "        X[i, :, 1] = X_[i, 16:]\n",
    "    y_true = np.concatenate((np.ones(250, dtype='int'), -1*np.ones(n_outliers, dtype='int')))\n",
    "\n",
    "    num_batch = len(X) \n",
    "    inds_shuffle = np.arange(num_batch)\n",
    "    np.random.shuffle(inds_shuffle)\n",
    "    X = X[inds_shuffle]\n",
    "    y_true = y_true[inds_shuffle]\n",
    "    y_trues.append(y_true)\n",
    "    \n",
    "    # SIG\n",
    "    dsig = dyadic_sig(X, level, 0)\n",
    "    dsig = dsig.reshape(dsig.shape[0], dsig.shape[1]*dsig.shape[2])\n",
    "    similarity_sig = pairwise_distances(dsig, metric = 'euclidean', n_jobs = -1)    \n",
    "    clf = LocalOutlierFactor(**lof_params)\n",
    "    clf.fit_predict(similarity_sig)\n",
    "    y_scores['sig'].append(-clf.negative_outlier_factor_)    \n",
    "\n",
    "    # MSIG\n",
    "    dsig = dyadic_sig(X, level, dyadic_depth)\n",
    "    dsig = dsig.reshape(dsig.shape[0], dsig.shape[1]*dsig.shape[2])\n",
    "    similarity_sig = pairwise_distances(dsig, metric = 'euclidean', n_jobs = -1)    \n",
    "    clf = LocalOutlierFactor(**lof_params)\n",
    "    clf.fit_predict(similarity_sig)\n",
    "    y_scores['dsig'].append(-clf.negative_outlier_factor_)\n",
    "\n",
    "    # DTW\n",
    "    similarity_dtw = dtw_ndim.distance_matrix_fast(X)\n",
    "    clf = LocalOutlierFactor(**lof_params)\n",
    "    clf.fit_predict(similarity_dtw)\n",
    "    y_scores['dtw'].append(-clf.negative_outlier_factor_)\n",
    "\n",
    "    # EUC\n",
    "    similarity_euc = pairwise_distances(X_, metric = 'euclidean', n_jobs = -1)   \n",
    "    clf = LocalOutlierFactor(**lof_params)\n",
    "    clf.fit_predict(similarity_euc)\n",
    "    y_scores['euc'].append(-clf.negative_outlier_factor_)\n",
    "    \n",
    "\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "with open(f'./outputs/dataset2/y_scores_{current_time}.pkl', 'wb') as f:\n",
    "    pickle.dump(y_scores, f)\n",
    "with open(f'./outputs/dataset2/y_trues_{current_time}.pkl', 'wb') as f:\n",
    "    pickle.dump(y_trues, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "518870b4-012f-432b-aa26-56aa831a6bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sig', 'dsig', 'dtw', 'euc'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_scores.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c321db-d012-4505-b718-49fe3364b6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4809f6c2-24cc-4a1c-a7bf-eda3c98064ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e341d5-271b-429b-8901-786fd2813649",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
